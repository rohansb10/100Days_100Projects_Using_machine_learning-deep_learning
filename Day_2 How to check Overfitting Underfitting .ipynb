{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47be79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c3edac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:28:32.264241Z",
     "start_time": "2024-03-24T13:28:31.048728Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ac1413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:54:38.259750Z",
     "start_time": "2024-03-24T13:54:38.245058Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Rohan\\Pictures\\rohan\\NLP\\preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b54b8677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:54:39.064963Z",
     "start_time": "2024-03-24T13:54:39.052369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>music</td>\n",
       "      <td>walk cloud wrap ancient symbolsw descend hill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>music</td>\n",
       "      <td>thick brushthey spend hottest part day , soak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>music</td>\n",
       "      <td>storm gener . someth easi surrend , sit window...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>music</td>\n",
       "      <td>—after ana mendieta carri around matin star ? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>music</td>\n",
       "      <td>aja sherrard 20the portent may memori . —walla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre                                               Poem\n",
       "0  music  walk cloud wrap ancient symbolsw descend hill ...\n",
       "1  music  thick brushthey spend hottest part day , soak ...\n",
       "2  music  storm gener . someth easi surrend , sit window...\n",
       "3  music  —after ana mendieta carri around matin star ? ...\n",
       "4  music  aja sherrard 20the portent may memori . —walla..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "002010de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:54:39.885841Z",
     "start_time": "2024-03-24T13:54:39.877844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(841, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475dc193",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:54:42.371854Z",
     "start_time": "2024-03-24T13:54:42.360195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfafc2b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:55:32.434238Z",
     "start_time": "2024-03-24T13:55:32.425392Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates( keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "539b8453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:55:35.703309Z",
     "start_time": "2024-03-24T13:55:35.692873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genre    0\n",
       "Poem     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc187c5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:55:36.825495Z",
     "start_time": "2024-03-24T13:55:36.817625Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a291a9e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:55:39.685945Z",
     "start_time": "2024-03-24T13:55:39.676113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(835, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a34aad9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:56:07.632876Z",
     "start_time": "2024-03-24T13:56:07.616849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genre\n",
       "music          238\n",
       "death          229\n",
       "environment    227\n",
       "affection      141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4552d7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa2ca22f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:57:08.679236Z",
     "start_time": "2024-03-24T13:57:08.653602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genre\n",
       "1    238\n",
       "0    229\n",
       "2    227\n",
       "3    141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genre'] = df['Genre'].replace({'affection': 3, 'environment':2 ,'music': 1, 'death': 0})\n",
    "df['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "638bb9f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:57:17.683902Z",
     "start_time": "2024-03-24T13:57:17.671222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>walk cloud wrap ancient symbolsw descend hill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>thick brushthey spend hottest part day , soak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>storm gener . someth easi surrend , sit window...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>—after ana mendieta carri around matin star ? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>aja sherrard 20the portent may memori . —walla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre                                               Poem\n",
       "0      1  walk cloud wrap ancient symbolsw descend hill ...\n",
       "1      1  thick brushthey spend hottest part day , soak ...\n",
       "2      1  storm gener . someth easi surrend , sit window...\n",
       "3      1  —after ana mendieta carri around matin star ? ...\n",
       "4      1  aja sherrard 20the portent may memori . —walla..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b10a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e9034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df154c9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T13:58:41.215922Z",
     "start_time": "2024-03-24T13:58:39.750727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poem</th>\n",
       "      <th>Poem_preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>walk cloud wrap ancient symbolsw descend hill ...</td>\n",
       "      <td>walk cloud wrap ancient symbolsw descend hill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>thick brushthey spend hottest part day , soak ...</td>\n",
       "      <td>thick brushthey spend hottest part day soak ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>storm gener . someth easi surrend , sit window...</td>\n",
       "      <td>storm gener someth easi surrend sit window ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>—after ana mendieta carri around matin star ? ...</td>\n",
       "      <td>ana mendieta carri around matin star hold fore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>aja sherrard 20the portent may memori . —walla...</td>\n",
       "      <td>aja sherrard portent may memori wallac stevens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre                                               Poem  \\\n",
       "0      1  walk cloud wrap ancient symbolsw descend hill ...   \n",
       "1      1  thick brushthey spend hottest part day , soak ...   \n",
       "2      1  storm gener . someth easi surrend , sit window...   \n",
       "3      1  —after ana mendieta carri around matin star ? ...   \n",
       "4      1  aja sherrard 20the portent may memori . —walla...   \n",
       "\n",
       "                                Poem_preprocess_text  \n",
       "0  walk cloud wrap ancient symbolsw descend hill ...  \n",
       "1  thick brushthey spend hottest part day soak ho...  \n",
       "2  storm gener someth easi surrend sit window ste...  \n",
       "3  ana mendieta carri around matin star hold fore...  \n",
       "4  aja sherrard portent may memori wallac stevens...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Define a function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and punctuations\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Stemming (using Porter Stemmer)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply the preprocessing function to the 'combined_text' column\n",
    "df['Poem_preprocess_text'] = df['Poem'].apply(preprocess_text)\n",
    "\n",
    "# Display the DataFrame with preprocessed text\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a07e6cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:11:13.063178Z",
     "start_time": "2024-03-24T14:11:13.053415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'—after ana mendieta carri around matin star ? hold forest-fir one hand ? would wake radiat , shimmer , gleam lucero-light ? morn would measur wingspan idea take off— & night would'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Poem[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a793da61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:11:20.275545Z",
     "start_time": "2024-03-24T14:11:20.267497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ana mendieta carri around matin star hold forestfir one hand would wake radiat shimmer gleam lucerolight morn would measur wingspan idea take night would'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Poem_preprocess_text[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc134bdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:13:20.099044Z",
     "start_time": "2024-03-24T14:13:20.089599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rohan barad u an que with'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text('i am rohan barad , how are u ans the que withs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e8620837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:24:05.687319Z",
     "start_time": "2024-03-24T17:24:05.673290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genre\n",
       "1    238\n",
       "0    229\n",
       "2    227\n",
       "3    141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b0531420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:26:05.286673Z",
     "start_time": "2024-03-24T17:26:05.243839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling: Counter({1: 238, 0: 229, 2: 227, 3: 141})\n",
      "After oversampling: Counter({1: 238, 0: 238, 3: 238, 2: 238})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "X = df.drop('Genre', axis=1)\n",
    "y = df['Genre']\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "df_resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "print('Before oversampling:', Counter(y))\n",
    "print('After oversampling:', Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8c667512",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:29:03.962550Z",
     "start_time": "2024-03-24T17:29:03.950085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85648075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532d1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1e0c58e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:29:10.813011Z",
     "start_time": "2024-03-24T17:29:10.651040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.48      0.51        46\n",
      "           1       0.45      0.51      0.48        41\n",
      "           2       0.59      0.39      0.47        49\n",
      "           3       0.61      0.78      0.68        55\n",
      "\n",
      "    accuracy                           0.55       191\n",
      "   macro avg       0.55      0.54      0.53       191\n",
      "weighted avg       0.55      0.55      0.54       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X = df_resampled['Poem_preprocess_text']\n",
    "y = df_resampled['Genre']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = nb_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy: 0.44\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.35      0.53      0.43        43\n",
    "           1       0.39      0.51      0.44        45\n",
    "           2       0.69      0.50      0.58        54\n",
    "           3       0.25      0.04      0.07        25\n",
    "\n",
    "    accuracy                           0.44       167\n",
    "   macro avg       0.42      0.40      0.38       167\n",
    "weighted avg       0.46      0.44      0.43       167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a41bb6c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:15:39.113807Z",
     "start_time": "2024-03-24T14:15:39.105606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Genre', 'Poem', 'Poem_preprocess_text'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a0fe09c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T16:01:05.961141Z",
     "start_time": "2024-03-24T16:01:05.954462Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# # Assuming 'df' is your DataFrame with columns 'news_type' and 'combined_text'\n",
    "# # Define X and y\n",
    "# X = df['Poem_preprocess_text']\n",
    "# y = df['Genre']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# # Initialize CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "\n",
    "# # Fit and transform the training data\n",
    "# X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "# \n",
    "# # Transform the test data\n",
    "# X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# # Display the shape of the vectorized data\n",
    "# print(\"Shape of X_train_vectorized:\", X_train_vectorized.shape)\n",
    "# print(\"Shape of X_test_vectorized:\", X_test_vectorized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cfd6d1c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:53:57.327112Z",
     "start_time": "2024-03-24T17:53:57.277885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.95\n",
      "Test Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.48      0.51        46\n",
      "           1       0.45      0.51      0.48        41\n",
      "           2       0.59      0.39      0.47        49\n",
      "           3       0.61      0.78      0.68        55\n",
      "\n",
      "    accuracy                           0.55       191\n",
      "   macro avg       0.55      0.54      0.53       191\n",
      "weighted avg       0.55      0.55      0.54       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train a Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Calculate training accuracy\n",
    "train_accuracy = nb_model.score(X_train_vectorized, y_train)\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}')\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = nb_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190f422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d6676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "607d27e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:29:36.701585Z",
     "start_time": "2024-03-24T17:29:30.200916Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5602094240837696\n",
      "Decision Tree Accuracy: 0.4869109947643979\n",
      "Random Forest Accuracy: 0.5497382198952879\n",
      "SVM Accuracy: 0.5602094240837696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "for name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train_vectorized, y_train)\n",
    "    y_pred = classifier.predict(X_test_vectorized)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f0aa5a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:30:36.428102Z",
     "start_time": "2024-03-24T17:29:50.896918Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "60 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rohan\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rohan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Rohan\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\Rohan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Rohan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Rohan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Rohan\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.25886653 0.25886653        nan        nan\n",
      " 0.25886653 0.25886653        nan        nan 0.44805642 0.44935501\n",
      "        nan        nan 0.48884589 0.49017028        nan        nan\n",
      " 0.48624011 0.49147747        nan        nan 0.47835397 0.48884589]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'classifier__C': 10, 'classifier__penalty': 'l2', 'vectorizer__ngram_range': (1, 2)}\n",
      "Testing Accuracy: 0.5863874345549738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters grid for tuning\n",
    "param_grid = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],  # Uni-gram or Bi-gram\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'classifier__penalty': ['l1', 'l2']  # Regularization penalty ('l1' for L1 regularization, 'l2' for L2 regularization)\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on testing data\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20caa60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:30:36.602546Z",
     "start_time": "2024-03-24T17:30:36.602546Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training accuracy\n",
    "train_accuracy = grid_search.best_score_\n",
    "print(\"Training Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc269663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4271e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "851a789c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:23:47.422885Z",
     "start_time": "2024-03-24T14:23:47.414926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Genre', 'Poem', 'Poem_preprocess_text'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b33d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:30:36.653673Z",
     "start_time": "2024-03-24T17:30:36.653673Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df_resampled['Poem_preprocess_text'])\n",
    "X_sequences = tokenizer.texts_to_sequences(df_resampled['Poem_preprocess_text'])\n",
    "X_padded = pad_sequences(X_sequences, maxlen=100)\n",
    "\n",
    "\n",
    "y_labels = df_resampled['Genre']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04bb4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:30:36.723683Z",
     "start_time": "2024-03-24T17:30:36.723683Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ... (previous code for data preprocessing)\n",
    "\n",
    "# Train-test split for DL\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(\n",
    "    X_padded, y_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Build a faster neural network\n",
    "dl_model = Sequential()\n",
    "dl_model.add(Embedding(input_dim=5000, output_dim=32, input_length=100))\n",
    "dl_model.add(Flatten())\n",
    "dl_model.add(BatchNormalization())\n",
    "dl_model.add(Dense(64, activation='relu'))\n",
    "dl_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Use Adam optimizer with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model\n",
    "dl_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping and model checkpoints\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "dl_model.fit(\n",
    "    X_train_dl, y_train_dl,\n",
    "    epochs=20, batch_size=32,\n",
    "    validation_data=(X_test_dl, y_test_dl),\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925bcf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:30:36.752689Z",
     "start_time": "2024-03-24T17:30:36.752689Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_results = dl_model.evaluate(X_test_dl, y_test_dl)\n",
    "\n",
    "# Extract accuracy from the evaluation results\n",
    "accuracy = eval_results[1]\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "183dc218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:34:32.187224Z",
     "start_time": "2024-03-24T14:34:24.659782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: -19792.0664 - accuracy: 0.2695\n",
      "Test Accuracy: 0.269461065530777\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - 0s 19ms/step - loss: -34931.7383 - accuracy: 0.3174 - val_loss: -23489.1387 - val_accuracy: 0.2695\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 0s 16ms/step - loss: -39690.0742 - accuracy: 0.3189 - val_loss: -27421.6504 - val_accuracy: 0.2695\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 0s 14ms/step - loss: -45421.6016 - accuracy: 0.3189 - val_loss: -31751.4785 - val_accuracy: 0.2695\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 0s 16ms/step - loss: -51767.9648 - accuracy: 0.3174 - val_loss: -36628.9570 - val_accuracy: 0.2695\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 0s 14ms/step - loss: -58655.7852 - accuracy: 0.3069 - val_loss: -41883.8125 - val_accuracy: 0.2695\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 0s 14ms/step - loss: -64847.6953 - accuracy: 0.3263 - val_loss: -47922.4883 - val_accuracy: 0.2695\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 0s 14ms/step - loss: -73278.1250 - accuracy: 0.3144 - val_loss: -53917.7773 - val_accuracy: 0.2695\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 0s 14ms/step - loss: -81514.3906 - accuracy: 0.3189 - val_loss: -60428.6523 - val_accuracy: 0.2695\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 0s 15ms/step - loss: -90442.8047 - accuracy: 0.3129 - val_loss: -67595.9297 - val_accuracy: 0.2695\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 0s 15ms/step - loss: -99728.8750 - accuracy: 0.3129 - val_loss: -74327.9844 - val_accuracy: 0.2695\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 0s 19ms/step - loss: -109815.5234 - accuracy: 0.3084 - val_loss: -82291.6875 - val_accuracy: 0.2695\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 1s 25ms/step - loss: -120915.1641 - accuracy: 0.3069 - val_loss: -90156.6250 - val_accuracy: 0.2695\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 0s 16ms/step - loss: -132361.3281 - accuracy: 0.3114 - val_loss: -98456.5469 - val_accuracy: 0.2695\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 0s 17ms/step - loss: -143779.7812 - accuracy: 0.3099 - val_loss: -108191.1406 - val_accuracy: 0.2695\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 0s 19ms/step - loss: -157236.5625 - accuracy: 0.3054 - val_loss: -117859.5234 - val_accuracy: 0.2635\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 0s 18ms/step - loss: -169042.9062 - accuracy: 0.3114 - val_loss: -127875.5078 - val_accuracy: 0.2635\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 0s 16ms/step - loss: -183304.7344 - accuracy: 0.3054 - val_loss: -138211.7188 - val_accuracy: 0.2695\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 0s 22ms/step - loss: -199201.3438 - accuracy: 0.3084 - val_loss: -149353.9219 - val_accuracy: 0.2695\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 0s 19ms/step - loss: -212811.4688 - accuracy: 0.3159 - val_loss: -160447.3594 - val_accuracy: 0.2695\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 0s 20ms/step - loss: -226946.8281 - accuracy: 0.3039 - val_loss: -172901.7031 - val_accuracy: 0.2695\n",
      "Training Accuracy: 0.30389222502708435\n"
     ]
    }
   ],
   "source": [
    "eval_results = dl_model.evaluate(X_test_dl, y_test_dl)\n",
    "\n",
    "# Extract accuracy from the evaluation results\n",
    "test_accuracy = eval_results[1]\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "\n",
    "history = dl_model.fit(\n",
    "    X_train_dl, y_train_dl,\n",
    "    epochs=20, batch_size=32,\n",
    "    validation_data=(X_test_dl, y_test_dl),\n",
    "    callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Extract training accuracy from the history object\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "print(\"Training Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c768b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20eafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbec63ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:39:13.275408Z",
     "start_time": "2024-03-24T14:39:13.265981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Genre', 'Poem', 'Poem_preprocess_text'], dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "327d1583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:40:05.148270Z",
     "start_time": "2024-03-24T14:39:24.996644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 - 10s - loss: 1.3789 - accuracy: 0.2904 - val_loss: 1.3693 - val_accuracy: 0.2695 - 10s/epoch - 871ms/step\n",
      "Epoch 2/10\n",
      "11/11 - 4s - loss: 1.3490 - accuracy: 0.3099 - val_loss: 1.3619 - val_accuracy: 0.3293 - 4s/epoch - 335ms/step\n",
      "Epoch 3/10\n",
      "11/11 - 3s - loss: 1.3036 - accuracy: 0.5659 - val_loss: 1.3587 - val_accuracy: 0.2934 - 3s/epoch - 309ms/step\n",
      "Epoch 4/10\n",
      "11/11 - 3s - loss: 1.1305 - accuracy: 0.6392 - val_loss: 1.3683 - val_accuracy: 0.3413 - 3s/epoch - 299ms/step\n",
      "Epoch 5/10\n",
      "11/11 - 3s - loss: 0.9249 - accuracy: 0.7964 - val_loss: 1.4366 - val_accuracy: 0.3772 - 3s/epoch - 317ms/step\n",
      "Epoch 6/10\n",
      "11/11 - 3s - loss: 0.6054 - accuracy: 0.8054 - val_loss: 1.6344 - val_accuracy: 0.4311 - 3s/epoch - 309ms/step\n",
      "Epoch 7/10\n",
      "11/11 - 3s - loss: 0.3907 - accuracy: 0.8997 - val_loss: 1.5059 - val_accuracy: 0.4132 - 3s/epoch - 300ms/step\n",
      "Epoch 8/10\n",
      "11/11 - 3s - loss: 0.2581 - accuracy: 0.9192 - val_loss: 1.8582 - val_accuracy: 0.4311 - 3s/epoch - 246ms/step\n",
      "Epoch 9/10\n",
      "11/11 - 3s - loss: 0.2088 - accuracy: 0.9311 - val_loss: 1.8198 - val_accuracy: 0.3772 - 3s/epoch - 314ms/step\n",
      "Epoch 10/10\n",
      "11/11 - 3s - loss: 0.2074 - accuracy: 0.9207 - val_loss: 1.8388 - val_accuracy: 0.3413 - 3s/epoch - 262ms/step\n",
      "Test loss: 1.838762879371643\n",
      "Test accuracy: 0.341317355632782\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['Poem_preprocess_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['Poem_preprocess_text'])\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df['Genre'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Definition\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Model Evaluation\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2331ade2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:43:57.552451Z",
     "start_time": "2024-03-24T14:42:52.924612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 - 13s - loss: 1.3835 - accuracy: 0.2740 - val_loss: 1.3760 - val_accuracy: 0.2695 - 13s/epoch - 2s/step\n",
      "Epoch 2/20\n",
      "6/6 - 2s - loss: 1.3705 - accuracy: 0.3159 - val_loss: 1.3641 - val_accuracy: 0.2934 - 2s/epoch - 389ms/step\n",
      "Epoch 3/20\n",
      "6/6 - 2s - loss: 1.3398 - accuracy: 0.3653 - val_loss: 1.3582 - val_accuracy: 0.2994 - 2s/epoch - 411ms/step\n",
      "Epoch 4/20\n",
      "6/6 - 3s - loss: 1.2990 - accuracy: 0.4476 - val_loss: 1.3562 - val_accuracy: 0.2754 - 3s/epoch - 477ms/step\n",
      "Epoch 5/20\n",
      "6/6 - 3s - loss: 1.1670 - accuracy: 0.4985 - val_loss: 1.3918 - val_accuracy: 0.2934 - 3s/epoch - 458ms/step\n",
      "Epoch 6/20\n",
      "6/6 - 3s - loss: 0.8695 - accuracy: 0.6781 - val_loss: 1.4212 - val_accuracy: 0.4371 - 3s/epoch - 432ms/step\n",
      "Epoch 7/20\n",
      "6/6 - 3s - loss: 0.6226 - accuracy: 0.8263 - val_loss: 1.6246 - val_accuracy: 0.3473 - 3s/epoch - 465ms/step\n",
      "Epoch 8/20\n",
      "6/6 - 3s - loss: 0.4819 - accuracy: 0.8608 - val_loss: 1.6354 - val_accuracy: 0.4251 - 3s/epoch - 450ms/step\n",
      "Epoch 9/20\n",
      "6/6 - 3s - loss: 0.3259 - accuracy: 0.9072 - val_loss: 1.6540 - val_accuracy: 0.4132 - 3s/epoch - 431ms/step\n",
      "Epoch 10/20\n",
      "6/6 - 2s - loss: 0.2659 - accuracy: 0.9207 - val_loss: 1.7184 - val_accuracy: 0.4311 - 2s/epoch - 410ms/step\n",
      "Epoch 11/20\n",
      "6/6 - 3s - loss: 0.2376 - accuracy: 0.9266 - val_loss: 1.9572 - val_accuracy: 0.4311 - 3s/epoch - 438ms/step\n",
      "Epoch 12/20\n",
      "6/6 - 3s - loss: 0.2864 - accuracy: 0.9057 - val_loss: 1.7675 - val_accuracy: 0.3772 - 3s/epoch - 446ms/step\n",
      "Epoch 13/20\n",
      "6/6 - 3s - loss: 0.2475 - accuracy: 0.9222 - val_loss: 1.7514 - val_accuracy: 0.4251 - 3s/epoch - 434ms/step\n",
      "Epoch 14/20\n",
      "6/6 - 3s - loss: 0.2202 - accuracy: 0.9296 - val_loss: 1.6452 - val_accuracy: 0.4012 - 3s/epoch - 446ms/step\n",
      "Epoch 15/20\n",
      "6/6 - 3s - loss: 0.2006 - accuracy: 0.9371 - val_loss: 1.6932 - val_accuracy: 0.4431 - 3s/epoch - 435ms/step\n",
      "Epoch 16/20\n",
      "6/6 - 3s - loss: 0.1767 - accuracy: 0.9356 - val_loss: 1.8237 - val_accuracy: 0.4491 - 3s/epoch - 433ms/step\n",
      "Epoch 17/20\n",
      "6/6 - 3s - loss: 0.1805 - accuracy: 0.9386 - val_loss: 1.8485 - val_accuracy: 0.4072 - 3s/epoch - 468ms/step\n",
      "Epoch 18/20\n",
      "6/6 - 3s - loss: 0.1632 - accuracy: 0.9371 - val_loss: 1.8430 - val_accuracy: 0.4251 - 3s/epoch - 443ms/step\n",
      "Epoch 19/20\n",
      "6/6 - 3s - loss: 0.1659 - accuracy: 0.9266 - val_loss: 1.8921 - val_accuracy: 0.4431 - 3s/epoch - 461ms/step\n",
      "Epoch 20/20\n",
      "6/6 - 3s - loss: 0.1564 - accuracy: 0.9311 - val_loss: 1.9248 - val_accuracy: 0.4431 - 3s/epoch - 476ms/step\n",
      "Test loss: 1.92482328414917\n",
      "Test accuracy: 0.443113774061203\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# Model Definition\n",
    "embedding_dim = 200  # Increased embedding dimension\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "\n",
    "# Adding multiple LSTM layers\n",
    "model.add(LSTM(128, return_sequences=True, dropout=0.2))\n",
    "model.add(LSTM(64, dropout=0.2))\n",
    "\n",
    "# Adding Dense layers\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "batch_size = 128\n",
    "epochs = 20  # Increased epochs\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Model Evaluation\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6448b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92ea1fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:47:04.559763Z",
     "start_time": "2024-03-24T14:44:43.548279Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 - 19s - loss: 2.0117 - accuracy: 0.2425 - val_loss: 1.9733 - val_accuracy: 0.2814 - 19s/epoch - 3s/step\n",
      "Epoch 2/20\n",
      "6/6 - 7s - loss: 1.9499 - accuracy: 0.3398 - val_loss: 1.9111 - val_accuracy: 0.2754 - 7s/epoch - 1s/step\n",
      "Epoch 3/20\n",
      "6/6 - 7s - loss: 1.8832 - accuracy: 0.3698 - val_loss: 1.8506 - val_accuracy: 0.2754 - 7s/epoch - 1s/step\n",
      "Epoch 4/20\n",
      "6/6 - 7s - loss: 1.8120 - accuracy: 0.3997 - val_loss: 1.8225 - val_accuracy: 0.3234 - 7s/epoch - 1s/step\n",
      "Epoch 5/20\n",
      "6/6 - 7s - loss: 1.6897 - accuracy: 0.5329 - val_loss: 1.7842 - val_accuracy: 0.3114 - 7s/epoch - 1s/step\n",
      "Epoch 6/20\n",
      "6/6 - 7s - loss: 1.4748 - accuracy: 0.5434 - val_loss: 1.7122 - val_accuracy: 0.4072 - 7s/epoch - 1s/step\n",
      "Epoch 7/20\n",
      "6/6 - 6s - loss: 1.3148 - accuracy: 0.6257 - val_loss: 1.6782 - val_accuracy: 0.3593 - 6s/epoch - 1s/step\n",
      "Epoch 8/20\n",
      "6/6 - 6s - loss: 1.1183 - accuracy: 0.7156 - val_loss: 1.8300 - val_accuracy: 0.3114 - 6s/epoch - 1s/step\n",
      "Epoch 9/20\n",
      "6/6 - 6s - loss: 0.8623 - accuracy: 0.8743 - val_loss: 2.3655 - val_accuracy: 0.2874 - 6s/epoch - 1s/step\n",
      "Epoch 10/20\n",
      "6/6 - 6s - loss: 0.7300 - accuracy: 0.8877 - val_loss: 2.6147 - val_accuracy: 0.2635 - 6s/epoch - 1s/step\n",
      "Epoch 11/20\n",
      "6/6 - 6s - loss: 0.6868 - accuracy: 0.8952 - val_loss: 2.4674 - val_accuracy: 0.2874 - 6s/epoch - 1s/step\n",
      "Epoch 12/20\n",
      "6/6 - 6s - loss: 0.6107 - accuracy: 0.9177 - val_loss: 2.4022 - val_accuracy: 0.3234 - 6s/epoch - 1s/step\n",
      "Epoch 13/20\n",
      "6/6 - 6s - loss: 0.5809 - accuracy: 0.9162 - val_loss: 2.4218 - val_accuracy: 0.3234 - 6s/epoch - 1s/step\n",
      "Epoch 14/20\n",
      "6/6 - 6s - loss: 0.5191 - accuracy: 0.9281 - val_loss: 2.3945 - val_accuracy: 0.3413 - 6s/epoch - 1s/step\n",
      "Epoch 15/20\n",
      "6/6 - 6s - loss: 0.5087 - accuracy: 0.9311 - val_loss: 2.7158 - val_accuracy: 0.3293 - 6s/epoch - 1s/step\n",
      "Epoch 16/20\n",
      "6/6 - 6s - loss: 0.5035 - accuracy: 0.9177 - val_loss: 2.6182 - val_accuracy: 0.3653 - 6s/epoch - 1s/step\n",
      "Epoch 17/20\n",
      "6/6 - 6s - loss: 0.4537 - accuracy: 0.9281 - val_loss: 2.6332 - val_accuracy: 0.3293 - 6s/epoch - 1s/step\n",
      "Epoch 18/20\n",
      "6/6 - 6s - loss: 0.4340 - accuracy: 0.9281 - val_loss: 2.3490 - val_accuracy: 0.3413 - 6s/epoch - 1s/step\n",
      "Epoch 19/20\n",
      "6/6 - 6s - loss: 0.4371 - accuracy: 0.9371 - val_loss: 2.5397 - val_accuracy: 0.3353 - 6s/epoch - 1s/step\n",
      "Epoch 20/20\n",
      "6/6 - 6s - loss: 0.3978 - accuracy: 0.9311 - val_loss: 2.8248 - val_accuracy: 0.2934 - 6s/epoch - 1s/step\n",
      "Test loss: 2.82476544380188\n",
      "Test accuracy: 0.2934131622314453\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Model Definition\n",
    "embedding_dim = 200\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "\n",
    "# Adding multiple LSTM layers with dropout and recurrent dropout\n",
    "model.add(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "# Adding Dense layers with regularization\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Model Evaluation\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b29bc2ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T16:25:04.350597Z",
     "start_time": "2024-03-24T16:24:43.550264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 [==============================] - 8s 147ms/step - loss: 0.5563 - accuracy: 0.2943 - val_loss: -1.0142 - val_accuracy: 0.2695\n",
      "Epoch 2/10\n",
      " 2/21 [=>............................] - ETA: 0s - loss: -0.6554 - accuracy: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 60ms/step - loss: -1.5831 - accuracy: 0.2889 - val_loss: -2.5986 - val_accuracy: 0.2695\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 1s 61ms/step - loss: -2.8268 - accuracy: 0.2889 - val_loss: -3.6412 - val_accuracy: 0.2695\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 1s 60ms/step - loss: -3.5783 - accuracy: 0.2889 - val_loss: -4.4032 - val_accuracy: 0.2695\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 1s 59ms/step - loss: -4.1771 - accuracy: 0.2889 - val_loss: -4.9173 - val_accuracy: 0.2695\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 1s 60ms/step - loss: -4.5659 - accuracy: 0.2889 - val_loss: -5.2875 - val_accuracy: 0.2695\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 1s 60ms/step - loss: -4.7552 - accuracy: 0.2889 - val_loss: -5.3259 - val_accuracy: 0.2695\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 1s 61ms/step - loss: -4.7842 - accuracy: 0.2889 - val_loss: -5.3490 - val_accuracy: 0.2695\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 1s 60ms/step - loss: -4.8039 - accuracy: 0.2889 - val_loss: -5.3672 - val_accuracy: 0.2695\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 1s 60ms/step - loss: -4.8182 - accuracy: 0.2889 - val_loss: -5.3798 - val_accuracy: 0.2695\n",
      "6/6 [==============================] - 0s 21ms/step - loss: -5.3798 - accuracy: 0.2695\n",
      "LSTM Test Accuracy: 0.269461065530777\n",
      "LSTM Training Accuracy: 0.28892216086387634\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=5000, output_dim=32, input_length=100))\n",
    "lstm_model.add(LSTM(64, kernel_regularizer=regularizers.l2(0.01), return_sequences=True)) \n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping and model checkpoints\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_lstm_model.h5', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "lstm_history = lstm_model.fit(\n",
    "    X_train_dl, y_train_dl,\n",
    "    epochs=10, batch_size=32,\n",
    "    validation_data=(X_test_dl, y_test_dl),\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the LSTM model on the test set\n",
    "lstm_eval_results = lstm_model.evaluate(X_test_dl, y_test_dl)\n",
    "\n",
    "# Extract accuracy from the evaluation results\n",
    "lstm_test_accuracy = lstm_eval_results[1]\n",
    "print(\"LSTM Test Accuracy:\", lstm_test_accuracy)\n",
    "\n",
    "# Extract training accuracy from the LSTM history object\n",
    "lstm_train_accuracy = lstm_history.history['accuracy'][-1]\n",
    "print(\"LSTM Training Accuracy:\", lstm_train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60bde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df0edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "162d4f3a",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a1686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c1ba876a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T18:00:50.826837Z",
     "start_time": "2024-03-24T18:00:50.474950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.95\n",
      "Test Accuracy: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.43      0.48        46\n",
      "           1       0.43      0.61      0.51        41\n",
      "           2       0.57      0.47      0.52        49\n",
      "           3       0.71      0.71      0.71        55\n",
      "\n",
      "    accuracy                           0.56       191\n",
      "   macro avg       0.56      0.56      0.55       191\n",
      "weighted avg       0.57      0.56      0.56       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(penalty='l2',random_state=21)\n",
    "LR.fit(X_train_vectorized, y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test_vectorized)\n",
    "\n",
    "# Calculate training accuracy\n",
    "train_accuracy = nb_model.score(X_train_vectorized, y_train)\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9af5be5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T17:58:31.571913Z",
     "start_time": "2024-03-24T17:58:31.538946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.95\n",
      "Test Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.48      0.51        46\n",
      "           1       0.45      0.51      0.48        41\n",
      "           2       0.59      0.39      0.47        49\n",
      "           3       0.61      0.78      0.68        55\n",
      "\n",
      "    accuracy                           0.55       191\n",
      "   macro avg       0.55      0.54      0.53       191\n",
      "weighted avg       0.55      0.55      0.54       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train a Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Calculate training accuracy\n",
    "train_accuracy = nb_model.score(X_train_vectorized, y_train)\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}')\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = nb_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acb541",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "81497843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T18:01:39.030570Z",
     "start_time": "2024-03-24T18:01:38.999964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poem</th>\n",
       "      <th>Poem_preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>3</td>\n",
       "      <td>, never except thirti second year ecstasi come...</td>\n",
       "      <td>never except thirti second year ecstasi come l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>3</td>\n",
       "      <td>nobodyuntil anoth man leavesa note wiper : lik...</td>\n",
       "      <td>nobodyuntil anoth man leavesa note wiper like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1</td>\n",
       "      <td>know pretendsto broken wing tolur predat away ...</td>\n",
       "      <td>know pretendsto broken wing tolur predat away ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0</td>\n",
       "      <td>second ago heart thump went thought , `` would...</td>\n",
       "      <td>second ago heart thump went thought would bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>3</td>\n",
       "      <td>'s madg , madg men ? buri alic hair , ( ask ra...</td>\n",
       "      <td>madg madg men buri alic hair ask rain tell bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>3</td>\n",
       "      <td>sens world short , —long variou report , — lov...</td>\n",
       "      <td>sen world short long variou report love belov ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>2</td>\n",
       "      <td>fuchsia funnel break outof crabappl tree , nei...</td>\n",
       "      <td>fuchsia funnel break outof crabappl tree neigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>pretti girl . weather knock given lake wear sk...</td>\n",
       "      <td>pretti girl weather knock given lake wear skin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>3</td>\n",
       "      <td>door open saw thereand first time heard speak ...</td>\n",
       "      <td>door open saw thereand first time heard speak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>3</td>\n",
       "      <td>true love humbl , low-born thing , hath food s...</td>\n",
       "      <td>true love humbl lowborn thing hath food serv e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Genre                                               Poem  \\\n",
       "609      3  , never except thirti second year ecstasi come...   \n",
       "606      3  nobodyuntil anoth man leavesa note wiper : lik...   \n",
       "233      1  know pretendsto broken wing tolur predat away ...   \n",
       "265      0  second ago heart thump went thought , `` would...   \n",
       "598      3  's madg , madg men ? buri alic hair , ( ask ra...   \n",
       "540      3  sens world short , —long variou report , — lov...   \n",
       "729      2  fuchsia funnel break outof crabappl tree , nei...   \n",
       "393      0  pretti girl . weather knock given lake wear sk...   \n",
       "535      3  door open saw thereand first time heard speak ...   \n",
       "559      3  true love humbl , low-born thing , hath food s...   \n",
       "\n",
       "                                  Poem_preprocess_text  \n",
       "609  never except thirti second year ecstasi come l...  \n",
       "606  nobodyuntil anoth man leavesa note wiper like ...  \n",
       "233  know pretendsto broken wing tolur predat away ...  \n",
       "265  second ago heart thump went thought would bad ...  \n",
       "598  madg madg men buri alic hair ask rain tell bea...  \n",
       "540  sen world short long variou report love belov ...  \n",
       "729  fuchsia funnel break outof crabappl tree neigh...  \n",
       "393  pretti girl weather knock given lake wear skin...  \n",
       "535  door open saw thereand first time heard speak ...  \n",
       "559  true love humbl lowborn thing hath food serv e...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1152ca4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T18:05:06.230891Z",
     "start_time": "2024-03-24T18:05:06.224666Z"
    }
   },
   "outputs": [],
   "source": [
    "Text = [df.Poem[606]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6a41e34f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T18:05:11.929483Z",
     "start_time": "2024-03-24T18:05:11.914955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genre: [3]\n"
     ]
    }
   ],
   "source": [
    "# Example user input text\n",
    "user_input = Text\n",
    "df['Genre'] = df['Genre'].replace({'affection': 3, 'environment':2 ,'music': 1, 'death': 0})\n",
    "user_input_vectorized = vectorizer.transform(user_input)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "user_predictions = LR.predict(user_input_vectorized)\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predicted Genre:\", user_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "233837d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T18:05:12.614781Z",
     "start_time": "2024-03-24T18:05:12.592259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genre: affection\n"
     ]
    }
   ],
   "source": [
    "# Mapping genre labels to numeric values\n",
    "label_mapping = {'affection': 3, 'environment': 2, 'music': 1, 'death': 0}\n",
    "\n",
    "user_input = Text\n",
    "user_input_vectorized = vectorizer.transform(user_input)\n",
    "\n",
    "user_predictions = nb_model.predict(user_input_vectorized)\n",
    "\n",
    "predicted_genre = [k for k, v in label_mapping.items() if v == user_predictions[0]][0]\n",
    "\n",
    "print(\"Predicted Genre:\", predicted_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285eab8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0ab3bd6",
   "metadata": {},
   "source": [
    "# This model is not good becouse the data is small and the model is \n",
    "\n",
    "Training Accuracy: 0.95\n",
    "Test Accuracy: 0.55\n",
    "    \n",
    "so means model is traing good but test accuracy is bad so this model is overfit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d290aa4",
   "metadata": {},
   "source": [
    "In summary, the provided model is likely overfitting the training data,\n",
    "as indicated by the large gap between the training and test accuracies. \n",
    "To address this, you may need to consider reducing the complexity of the model,\n",
    "gathering more training data, or applying regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be03e2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
