{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Dataset\n",
        "\n",
        "\n",
        "Pre-processing the raw data\n",
        "\n",
        "\n",
        "Getting BERT Pre-trained model and its tokenizer\n",
        "\n",
        "\n",
        "Training and evaluation\n",
        "\n",
        "\n",
        "Prediction Pipeline\n",
        "\n",
        "\n",
        "# Loading the Dataset"
      ],
      "metadata": {
        "id": "L7sWeMwl5e81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"bbc-text.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-TTluhAK5kFK",
        "outputId": "9c393e6d-6e97-4d31-9bdb-b9aee7facf21"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be6a7445-0874-4bb0-9ccf-f77073fef3d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be6a7445-0874-4bb0-9ccf-f77073fef3d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be6a7445-0874-4bb0-9ccf-f77073fef3d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be6a7445-0874-4bb0-9ccf-f77073fef3d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-84d37060-c45e-4220-a9a9-313e668e6e78\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84d37060-c45e-4220-a9a9-313e668e6e78')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-84d37060-c45e-4220-a9a9-313e668e6e78 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2225,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"business\",\n          \"politics\",\n          \"sport\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2126,\n        \"samples\": [\n          \"plan to give elderly care control elderly and disabled people would choose how their own budget for personal care was spent and organised under government plans.  ministers say elderly and disabled people themselves  not social workers  should be able to decide on their care and stay in their own homes. they also plan a supremo for adult services in each english area to get different agencies working together. but the government shunned opponents  calls for free long-term care.  there are 1.7m people needing care in england and ministers suggest the number could quadruple by 2050. monday s consultation paper on social care for adults in england is aimed at ending a system which generates dependency. health minister stephen ladyman said:  this document is the antithesis of the nanny state.   it s about taking power away from the state and giving it to individuals and saying that we will help you make these decisions but we are not going to make them for you any more.  the government has already allowed local councils to give people money so they can pay for their services directly but take-up of the scheme has been  disappointing .  ministers say the new plans would make direct payments simpler and try to counter reluctance in some local councils to use the payments. they also want to set up a new  half-way house  where social workers tell people how much money is available for their care and help them choose how to spend that  individual budget . the scheme will be funded on existing budgets set until 2008. but mr ladyman said the plans could deliver savings in some areas  such as freeing up nhs beds and preventing illnesses. he ruled out free personal care in england - which is on offer in scotland and wales  saying it was  unsustainable .  david rogers  from the local government association  said agencies were working together on the kind of innovation proposed by the government. and tony hunter  president of the association of directors of social services  said the plans could improve dignity and well-being for thousands of people. but age concern argued social care was chronically under-funded and older people were being offered choice in principle  but not in practice. its director general  gordon lishman  said:  direct payments will not work if there are no services for people to choose from locally.   the tories say people who pay for three years  long-term care directly or through insurance should be guaranteed free care for the rest of their lives. tory spokesman simon burns said more than 80 000 long term care places had been lost since 1997.  after eight years of persistent change  dogmatic enforcement of regulation  and overbearing government initiatives - we need action  not a vision   said mr burns. the lib dems say they would fund free personal care by a new 50% tax rate on incomes over \\u00a3100 000. health spokesman paul burstow said:  promoting independence sounds good and helping people to live in their own homes is a goal we share.  but the risk is that independence can turn into isolation if the right support and care is not available.\",\n          \"beer giant swallows russian firm brewing giant inbev has agreed to buy alfa-eco s stake in sun interbrew  russia s second-largest brewer  for up to 259.7m euros ($353.3m; \\u00a3183.75m).  alfa-eco  the venture capital arm of russian conglomerate alfa group  has a one-fifth stake in sun interbrew. the deal gives inbev  the world s biggest beermaker  near-total control over the russian brewer. inbev bought out another partner in august 2004. inbev brands include bass  stella artois  hoegaarden and staropramen. it employs 77 000 people  running operations in over 30 countries across the americas  europe and asia pacific.  the leuven-based brewery said it would own 97.3% of the voting shares and 98.8% of the non-voting shares of sun interbrew. the deal is expected to be completed in the first quarter of 2005. inbev was formed in august 2004 when belgium s interbrew bought brazilian brewer ambev. sun interbrew  which employs 8 000 staff  owns breweries in eight russian cities - klin  ivanovo  saransk  kursk  volzhsky  omsk  perm and novocheboksarsk. there are also three breweries in ukraine  in the cities of chernigov  nikolaev and kharkov.\",\n          \"athens memories soar above lows well  it s goodbye to another olympic year and as usual there were plenty of highs and lows in athens.  obviously  there s no getting away from the differing fortunes of kelly holmes and paula radcliffe. but i want to remind you of a few more events that made 2004 another year to remember - or forget - for athletics.      one of my favourite olympic moments was kelly s success in the 800m.  winning that race was the key to her success because if she won that then the 1500m would be a bit of a formality. kelly had been full of  should i  shouldn t i   thoughts about going for the double in athens. i thought why wouldn t you do the 800m  it s your best event  it was such good fun to commentate on her 1500m and it was nice to be able to be part of her athens story.      the victory for the british men s 4x100m relay team was a bit of a surprise but a great climax to the games. i think the four of them - jason gardener  darren campbell  marlon devonish and mark lewis-francis - knew deep down that it was their best chance of a medal. the lads had run poorly in the individual sprints so maybe they did lift their game when they knew something was really at stake.      hicham el guerrouj s olympic double is a much bigger achievement than kelly s on a global scale.  he was the first man since for 80 years to win both the 1500m and 5 000m titles. as soon as he had added the 5 000m crown and i had finished commentating  i jumped up  ran down the stairs  pushed everyone out the way and just gave him a big hug. he is one of the few african runners who has embraced the tradition of the mile and he loves to hear all the roger bannister stories. hicham is someone i enjoy having a bit of time with  even though my french and his english are not very good.      what happened to paula in athens this year is the obvious low on a personal level and for the expectations of the nation as well. there were a set of circumstances around athens that conspired to produce a very dramatic ending which i think has been greatly misunderstood. dropping out of the marathon was the right thing to do but starting in the 10 000m five days later was not wise. that was her heart and not her head reacting. paula had a lot of little things going wrong in her preparation and on the day.  things like niggling injuries  not being able to do all her running sessions and feeling the pressure of the race looming ahead of her. i think she came to the start line in athens physically and emotionally drained. and if even the smallest thing doesn t feel right when you are preparing to race a marathon  10 miles down the road it will hit you like a brick wall. the positive thing to take from paula s olympics it that she will have learned a lot from it and so will a lot of people - including me.      purely as a race  paula s victory in the new york marathon has to go down as one of the most thrilling. it was so nip-and-tuck between her and kenya s susan chepkemei and you don t usually get that kind of excitement in marathons. it was also a real delight for all athletics fans because  to use one of my favourite words  paula showed real  bouncebackability . and it was a bit of a rarity for me too because i genuinely did not have an inkling how the race was going to pan out.      kelly and the 4x100m boys  victories papered over the cracks in the general performance of the british team. we should be concerned that we re not producing enough people who are capable of reaching finals at senior level.  the only individual men s finalist on the track was michael east in the 1500m. i am beginning to look down and wonder where are the new breed  and that s where things begin to look even gloomier for british athletics as we did not win any medals at the world junior championships in italy. dani barnes came fourth in the 1500m and she was the highest finisher for team gb. the thing is if we don t have athletes getting into the finals at junior level then it really doesn t look good for the beijing olympics and beyond.      i tell you what i really enjoyed this year  benita johnson winning the world cross country championships back in march. in the absence of paula  we tend to think of the event as something of an african preserve. so to have an australian come up and deliver such a surprise was something special.      to be honest  i m getting bored with all the drug scandals  especially balco. i just wish the whole thing would come to a head so we can move on.  having said that  i m always pleased when drugs cheats are caught because it shows the sport is standing up to it and not turning a blind eye anymore. and one of the positive things to come out of balco is people are starting to blow the whistle. we need more people to come forward and help the authorities kick out the cheats. as regards the case against greek sprinters kostas kenteris and katerina thanou  well suspicions have been hanging over kenteris for a while. the bottom line is we cannot keep letting drugs damage the sport because if we do then it stops everyone enjoying it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngozDvPQPihG",
        "outputId": "ff821e21-c8d6-44f4-fa97-c561fe95df0f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category    0\n",
              "text        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balacing Classes"
      ],
      "metadata": {
        "id": "reP7_fr5Ghj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from imblearn.over_sampling import RandomOverSampler\n",
        "# # Step 2: Initialize RandomOverSampler\n",
        "# oversampler = RandomOverSampler(random_state=42)\n",
        "\n",
        "# # Step 3: Fit RandomOverSampler to the data\n",
        "# X = df['text'].values.reshape(-1, 1)  # Reshape to 2D array\n",
        "# y = df['category']\n",
        "# X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "# # Step 4: Resample the data to balance the classes\n",
        "\n",
        "# # Step 5: Split the resampled data into features and target columns\n",
        "# df = pd.DataFrame({'text': X_resampled.flatten(), 'category': y_resampled})"
      ],
      "metadata": {
        "id": "frFEJUvSGIRj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhf9AgkrGmKW",
        "outputId": "2dc10863-4243-45f2-ead9-a4ee10acea9c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2225, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test Set"
      ],
      "metadata": {
        "id": "HTziIql8GFPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Split the DataFrame into train and test sets\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n",
        "\n",
        "# Display the first few rows of each DataFrame\n",
        "print(\"Train Set:\")\n",
        "print(df_train.shape)\n",
        "\n",
        "print(\"\\nTest Set:\")\n",
        "print(df_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6LkWyWbNZJ1",
        "outputId": "1d477732-f677-4fb1-b16f-d4bd24fe7b78"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set:\n",
            "(1780, 2)\n",
            "\n",
            "Test Set:\n",
            "(445, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpzk3E7FN2lC",
        "outputId": "d015429b-bedd-43ca-9628-e2e9051dddee"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            413\n",
              "business         409\n",
              "politics         334\n",
              "tech             319\n",
              "entertainment    305\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning Text"
      ],
      "metadata": {
        "id": "-MVi800_FicH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import re\n",
        "# import string\n",
        "# from nltk.corpus import stopwords\n",
        "# from nltk.stem import PorterStemmer\n",
        "# from nltk.tokenize import word_tokenize\n",
        "\n",
        "# def preprocess_text(text):\n",
        "#     # Lowercase the text\n",
        "#     text = text.lower()\n",
        "\n",
        "#     # Remove numbers\n",
        "#     text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "#     # Remove punctuation\n",
        "#     text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "#     # Remove URLs\n",
        "#     text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "#     # Remove emails\n",
        "#     text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
        "\n",
        "#     # Remove emojis\n",
        "#     emoji_pattern = re.compile(\"[\"\n",
        "#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "#                                u\"\\U00002702-\\U000027B0\"\n",
        "#                                u\"\\U000024C2-\\U0001F251\"\n",
        "#                                \"]+\", flags=re.UNICODE)\n",
        "#     text = emoji_pattern.sub(r'', text)\n",
        "\n",
        "#     # Tokenize the text\n",
        "#     tokens = word_tokenize(text)\n",
        "\n",
        "#     # Remove stop words\n",
        "#     stop_words = set(stopwords.words('english'))\n",
        "#     tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "#     # Stemming\n",
        "#     stemmer = PorterStemmer()\n",
        "#     tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "#     # Join tokens back into a single string\n",
        "#     text = ' '.join(tokens)\n",
        "\n",
        "#     return text\n",
        "\n",
        "\n",
        "# df['clean_text'] = df['text'].apply(lambda x: preprocess_text(x))"
      ],
      "metadata": {
        "id": "g-2tnL-qFTQi"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting our Target column into Categorical data"
      ],
      "metadata": {
        "id": "LEzr2nuo5_Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVZbbTV3Rr1l",
        "outputId": "52e03405-3f28-41ce-bedf-4451726ca9c3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "business         101\n",
              "sport             98\n",
              "politics          83\n",
              "tech              82\n",
              "entertainment     81\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTlHElcNSYvo",
        "outputId": "deb02aa5-b17f-4f94-cdd1-adbe9777914b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(445, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dict = {\"sport\":0,\"business\":1, 'politics':2, \"entertainment\":3,'tech':4}\n",
        "df_train['category'] = df_train['category'].map(encoded_dict)"
      ],
      "metadata": {
        "id": "uU5nt6hK6B23"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['category'] = df_test['category'].map(encoded_dict)"
      ],
      "metadata": {
        "id": "qAm9r2oRScga"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "# Convert the 'category' column to categorical values\n",
        "y_train = to_categorical(df_train['category'])"
      ],
      "metadata": {
        "id": "-MnfpApV6Kjj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = to_categorical(df_test['category'])"
      ],
      "metadata": {
        "id": "TGhJbu8xS2Wq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8efhwIr9NgnY",
        "outputId": "70f968be-6993-46b2-db1a-f2e1aafeb117"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1780, 5), (445, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Model and Tokenizer from the transformers package"
      ],
      "metadata": {
        "id": "SfhC14sC6Sdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,TFBertModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "bert = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "t-SKuehR6KmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94ffa2b-14b0-4198-c843-babcd2a0401b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_train = max(len(text) for text in df_train['text'])\n",
        "max_len_test= max(len(text) for text in df_test['text'])"
      ],
      "metadata": {
        "id": "jBFHU3JCS7Xr"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_train, max_len_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQgHWvTbMtL5",
        "outputId": "f7dcfc72-2170-43e8-a2ee-6c2b4d2b7920"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19136, 25483)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input Data Modeling\n",
        "\n",
        "\n",
        "Before training, we need to convert the input textual data into BERT’s input data format using a tokenizer.\n",
        "\n",
        "Since we have loaded bert-base-cased, so tokenizer will also be Bert-base-cased."
      ],
      "metadata": {
        "id": "9oDjK_pI6ma8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Tokenize the input\n",
        "max_len = 70\n",
        "x_train = tokenizer(\n",
        "    text=df_train.text.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_len,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids=False,\n",
        "    return_attention_mask=True,\n",
        "    verbose=True\n",
        ")\n",
        "x_test = tokenizer(\n",
        "    text=df_test.text.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_len,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids=False,\n",
        "    return_attention_mask=True,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "tE6EtA356Kpj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer takes all the necessary parameters and returns tensor in the same format Bert accepts.\n",
        "\n",
        "return_token_type_ids = False: token_type_ids is not necessary for our training in this case.\n",
        "\n",
        "\n",
        "return_attention_mask = True we want to include attention_mask in our input.\n",
        "\n",
        "\n",
        "return_tensors=’tf’: we want our input tensor for the TensorFlow model.\n",
        "\n",
        "\n",
        "max_length=70:\n",
        "we want the maximum length of each sentence to be 70; if a sentence is\n",
        "bigger than this, it will be trimmed if a sentence is smaller than\n",
        "70 then it will be padded.\n",
        "\n",
        "add_special_tokens=True, CLS, SEP token will be added in the tokenization.\n",
        "\n",
        "\n",
        "Hereafter data modelling, the tokenizer will return a dictionary (x_train) containing ‘Input_ids’, ‘attention_mask’ as key for their respective"
      ],
      "metadata": {
        "id": "7HRbgu467goS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = x_train['input_ids']\n",
        "attention_mask = x_train['attention_mask']"
      ],
      "metadata": {
        "id": "ofBh5_St6Ksf"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"input ids:\",input_ids.shape)\n",
        "print(\"attention_mask:\", attention_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16uG4IA9Lkst",
        "outputId": "b8731a06-340e-474a-bed6-903a4e3c90af"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input ids: (1780, 70)\n",
            "attention_mask: (1780, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building\n",
        "\n",
        "## Importing necessary libraries.\n",
        "\n"
      ],
      "metadata": {
        "id": "z_rAfb9w8v6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense"
      ],
      "metadata": {
        "id": "z94qRaAO6Kv8"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layers\n",
        "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "input_ids.shape,input_mask.shape"
      ],
      "metadata": {
        "id": "G4FbCSt86K53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c504cacf-f8dd-41d9-c347-51234a83a3be"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([None, 70]), TensorShape([None, 70]))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model architecture (assuming 'bert' is already defined)\n",
        "embeddings = bert(input_ids, attention_mask=input_mask)[0]\n",
        "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32, activation='relu')(out)\n",
        "y = Dense(5, activation='sigmoid')(out)\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
        "model.layers[2].trainable = True"
      ],
      "metadata": {
        "id": "UZWyX7B_N2Js"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bert layers accept three input arrays, input_ids, attention_mask, token_type_ids\n",
        "\n",
        "\n",
        "input_ids means our input words encoding, then attention mask,\n",
        "\n",
        "\n",
        "token_type_ids is necessary for the question-answering model; in this case, we will not pass token_type_ids.\n",
        "\n",
        "\n",
        "For the Bert layer, we need two input layers, in this case, input_ids, attention_mask.\n",
        "\n",
        "\n",
        "Embeddings contain hidden states of the Bert layer.\n",
        "using\n",
        "\n",
        "\n",
        "GlobalMaxPooling1D then dense layer to build CNN layers using hidden\n",
        "states of Bert. These CNN layers will yield our output.\n",
        "bert[0] is the last hidden state, bert[1] is the\n",
        "pooler_output, for building CNN layers on top of the BERT layer, we have\n",
        "used Bert’s hidden forms."
      ],
      "metadata": {
        "id": "5LPzmBX09FA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Compilation\n",
        "Defining learning parameters and compiling the model.\n",
        "\n",
        "learning_rate = 5e-05 the learning rate for the model will be significantly lower.\n",
        "\n",
        "\n",
        "Loss = CategoricalCrossentropy since we are passing the categorical data as the target.\n",
        "\n",
        "\n",
        "Balanced accuracy will take care of our average accuracy for all the classes."
      ],
      "metadata": {
        "id": "pzjky4V79Xkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "\n",
        "# Define learning rate schedule\n",
        "initial_learning_rate = 5e-05\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=10000,  # Adjust this value according to your needs\n",
        "    decay_rate=0.01,    # Adjust this value according to your needs\n",
        "    staircase=True)\n",
        "# Define optimizer, loss, and metrics\n",
        "optimizer = Adam(\n",
        "    learning_rate=lr_schedule,\n",
        "    epsilon=1e-08,\n",
        "    clipnorm=1.0\n",
        ")\n",
        "loss = CategoricalCrossentropy(from_logits=True)\n",
        "metric = CategoricalAccuracy(name='balanced_accuracy')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metric\n",
        ")"
      ],
      "metadata": {
        "id": "539XdtUN9JnI"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "\n",
        "You have the model ready with x_train, y_train. You can now train the model.\n",
        "\n",
        "\n",
        "Training and fine-tuning of the BERT model takes a bit longer time. so be Patience.\n",
        "\n",
        "model.fit returns a history object which keeps all the training history.\n",
        "x_test became a dictionary containing ‘input_ids’, ‘attention_mask‘ after pre-processing. We are passing input_ids and attention_mask for the training.\n",
        "In the validation data, we are passing the test data.\n",
        "\n"
      ],
      "metadata": {
        "id": "G0Utj2QT9r3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_history = model.fit(\n",
        "    x={'input_ids': x_train['input_ids'], 'attention_mask': x_train['attention_mask']},\n",
        "    y=y_train,\n",
        "    validation_data=(\n",
        "        {'input_ids': x_test['input_ids'], 'attention_mask': x_test['attention_mask']},\n",
        "        y_test\n",
        "    ),\n",
        "    epochs=2,\n",
        "    batch_size=36\n",
        ")\n"
      ],
      "metadata": {
        "id": "VJVn3VuI9eeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4ac14a-fae0-4644-f839-a4d9f5c39722"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "50/50 [==============================] - 28s 560ms/step - loss: 0.0190 - balanced_accuracy: 0.9966 - val_loss: 0.0749 - val_balanced_accuracy: 0.9798\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 29s 583ms/step - loss: 0.0048 - balanced_accuracy: 0.9994 - val_loss: 0.0781 - val_balanced_accuracy: 0.9843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "Testing our model on the test data.\n"
      ],
      "metadata": {
        "id": "867Cxnmj99fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_raw = model.predict({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})\n",
        "predicted_raw[0]"
      ],
      "metadata": {
        "id": "G5Q-4rbF9ebK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea79a359-5019-4d95-eeb1-a60b29591f59"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 5s 150ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1674958 , 0.36198717, 0.9961494 , 0.23011458, 0.02928738],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking the index of value having maximum probability.\n",
        "import numpy as np\n",
        "y_predicted = np.argmax(predicted_raw, axis = 1)\n",
        "y_true = df_test.category\n",
        "y_true"
      ],
      "metadata": {
        "id": "l5NAj9As9eYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecaab8b3-54b0-4d24-f69e-1084cd813912"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "414     2\n",
              "420     1\n",
              "1644    3\n",
              "416     4\n",
              "1232    0\n",
              "       ..\n",
              "741     1\n",
              "205     1\n",
              "1102    1\n",
              "668     1\n",
              "479     1\n",
              "Name: category, Length: 445, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_predicted))"
      ],
      "metadata": {
        "id": "yZbuQrzQ-ntg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83c3379-3443-403b-bfa3-49630684aaf1"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        98\n",
            "           1       0.99      0.95      0.97       101\n",
            "           2       0.94      0.99      0.96        83\n",
            "           3       1.00      1.00      1.00        81\n",
            "           4       1.00      0.99      0.99        82\n",
            "\n",
            "    accuracy                           0.98       445\n",
            "   macro avg       0.98      0.99      0.98       445\n",
            "weighted avg       0.98      0.98      0.98       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Pipeline\n",
        "Converting indexes back to the Sentiment label:"
      ],
      "metadata": {
        "id": "i1FlbuIW-2kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "    x_val = tokenizer(\n",
        "        text=texts,\n",
        "        add_special_tokens=True,\n",
        "        max_length=70,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_tensors='tf',\n",
        "        return_token_type_ids=False,\n",
        "        return_attention_mask=True,\n",
        "        verbose=True\n",
        "    )\n",
        "    validation = model.predict({'input_ids': x_val['input_ids'], 'attention_mask': x_val['attention_mask']}) * 100\n",
        "\n",
        "    # Create lists to store the results\n",
        "    labels = []\n",
        "    scores = []\n",
        "\n",
        "    # Iterate over the predicted values and store them\n",
        "    for key, value in zip(encoded_dict.keys(), validation[0]):\n",
        "        labels.append(key)\n",
        "        scores.append(value)\n",
        "\n",
        "    # Get the predicted label with the highest score\n",
        "    predicted_label = labels[scores.index(max(scores))]\n",
        "\n",
        "    # Return the labels, scores, and the predicted label with its score\n",
        "    return labels, scores, predicted_label, max(scores)\n"
      ],
      "metadata": {
        "id": "bfVF9jYt-zbb"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = 'input the textbrown and blair face new rift claims for the umpteenth time  tony blair and gordon brown are said to have declared all out war on each other.  this time the alleged rift is over who should take the credit for the government s global aid and debt initiatives  particularly in the wake of the tsunami disaster - an issue many hoped and believed was above such things. it dominated the prime minister s monthly news conference  which saw mr blair start in full irritation mode as he was forced to bat away question after question about his relationship with his neighbour. as he told journalists:  i am not interested in what goes in and out of newspapers. there is a complete unity of purpose.  and he again heaped praise on mr brown saying he was doing a great job  and would continue doing it - although he would not commit to any job for mr brown after the election.  so why did he arrange his press conference at the last moment so it coincided with mr brown s long-arranged keynote speech on aid and debt  he was asked  by now mr blair had moved from irritation mode to his barely disguised fury setting. he snapped back that the hacks knew very well what the operational reasons were for the timing of his press conference. well  not really  as it happens.  and he repeated what a great man gordon was and how united they were  before again sneering that he took absolutely no notice of what went in and out of the newspapers  preferring to get on with the job of doing the best for the country and the world. although in the next breath he declared:  i get increasingly alarmed by what i read in the newspapers  before catching himself on and quickly adding:  in so far as i read them of course.  he probably had good reason to be alarmed because the newspapers had been full of stories about the claimed open warfare between the two men.  as far as the timing of the prime minister s press conference is concerned  there are two options. the first is that it was a calculated attempt to upstage the chancellor and seize back the initiative on the big issue of the moment. if that is the case it suggests that even the fear of seriously negative newspaper headlines is not enough to stop the squabbling. the second option is that it was an unavoidable coincidence  which would suggest the government has lost its once-famed ability to strictly co-ordinate announcements - through the infamous downing street grid - to avert just such allegations.  either way  the effect was the same - to overshadow the big announcements of government policy on a hugely pertinent issue. and there had been previous suggestions that the new year had started with a fresh outbreak of the warfare between the two men. firstly  the prime minister insisted on wednesday that he had been intimately involved in the development of the proposals to get g8 countries to freeze debt repayments from the tsunami-hit countries. it was claimed he had been embarrassed by the fact that gordon brown appeared to have taken the initiative over the government s response to the disaster while mr blair was still on holiday in egypt.  then  as if to pour fuel on the flames  both men separately spoke about working on tsunami or wider aid and development policy with their cabinet colleagues foreign secretary jack straw  aid minister hilary benn and deputy prime minister john prescott - without mentioning the other. all this came amid fresh claims that mr brown was still seething that he had been excluded from a prominent role in general election planning and had  as a result  started to set out his own platform. the fact that he used an article in the guardian newspaper to set out what he believed  should  be in the manifesto  has embarked on a mini tour of britain to set out his aid plans and will next week visit africa on the same mission - often seen as the prime minister s  turf  - has only added to the impression of rival camps operating entirely independently of each other. the prime minister denied all that as well  repeating his insistence that it was inconceivable the economy and the chancellor would not be at the centre of the election campaign. but the big fear with many on the labour benches now is that  unless a lid can be put on the speculation over the rivalry  it may even threaten to undermine the election campaign itself.'\n",
        "\n",
        "labels, scores, predicted_label, pred_prob = predict(texts)\n",
        "\n",
        "for name, score in zip(labels,scores):\n",
        "  print(\"Labels : \", name, \" Scores : \", score)\n",
        "\n",
        "print(\"====================================================\")\n",
        "print(\"predicted_label : \", predicted_label, \" Scores : \", pred_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXAaNKINamjo",
        "outputId": "0aced10a-ada6-4873-aa75-dc9649c5089b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "Labels :  sport  Scores :  19.24559\n",
            "Labels :  business  Scores :  29.926249\n",
            "Labels :  politics  Scores :  99.592834\n",
            "Labels :  entertainment  Scores :  24.017403\n",
            "Labels :  tech  Scores :  2.6347737\n",
            "====================================================\n",
            "predicted_label :  politics  Scores :  99.592834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts=\"housewives lift channel 4 ratings the debut of us television hit desperate housewives has helped lift channel 4 s january audience share by 12% compared to last year.  other successes such as celebrity big brother and the simpsons have enabled the broadcaster to surpass bbc two for the first month since last july. bbc two s share of the audience fell from 11.2% to 9.6% last month in comparison with january 2004. celebrity big brother attracted fewer viewers than its 2002 series.  comedy drama desperate housewives managed to pull in five million viewers at one point during its run to date  attracting a quarter of the television audience. the two main television channels  bbc1 and itv1  have both seen their monthly audience share decline in a year on year comparison for january  while five s proportion remained the same at a slender 6.3%. digital multi-channel tv is continuing to be the strongest area of growth  with the bbc reporting freeview box ownership of five million  including one million sales in the last portion of 2004. its share of the audience soared by 20% in january 2005 compared with last year  and currently stands at an average of 28.6%.\"\n",
        "labels, scores, predicted_label, pred_prob = predict(texts)\n",
        "\n",
        "for name, score in zip(labels,scores):\n",
        "  print(\"Labels : \", name, \" Scores : \", score)\n",
        "\n",
        "print(\"====================================================\")\n",
        "print(\"predicted_label : \", predicted_label, \" Scores : \", pred_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_juR0KGaOv5",
        "outputId": "b2ca05f4-1f51-400b-9e8b-a746a55581ce"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 229ms/step\n",
            "Labels :  sport  Scores :  7.9653106\n",
            "Labels :  business  Scores :  5.940966\n",
            "Labels :  politics  Scores :  1.3667592\n",
            "Labels :  entertainment  Scores :  99.69849\n",
            "Labels :  tech  Scores :  7.325931\n",
            "====================================================\n",
            "predicted_label :  entertainment  Scores :  99.69849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vZWjBZQocVAC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}